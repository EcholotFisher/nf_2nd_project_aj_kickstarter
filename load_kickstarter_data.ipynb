{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import glob\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kickstarter_data(datapath):\n",
    "    '''datapath = location of csv files to be loaded'''\n",
    "    # List with the names of all the csv files in the path\n",
    "    csv_files = glob.glob(datapath+'/*.csv')\n",
    "\n",
    "    print(f'Total files: {len(csv_files)}')\n",
    "\n",
    "    # Loop through the files\n",
    "    for file_idx, csv_file in enumerate(csv_files): \n",
    "        # create dataframe from 1st csv       \n",
    "        if file_idx == 0:\n",
    "            df_ks = pd.read_csv(csv_file)\n",
    "            print(f'File number {file_idx + 1} added to dataframe')\n",
    "        else:\n",
    "            # create dataframe from idx csv\n",
    "            df = pd.read_csv(csv_file)\n",
    "            # check files are all in same\n",
    "            if  np.all(df.columns == df_ks.columns) == False:\n",
    "                print(f'Column format of {csv_file} does not match {csv_files[0]}. Please check and try again')\n",
    "                return\n",
    "            else:\n",
    "                # append to initial dataframe                   \n",
    "                df_ks = pd.concat([df_ks, df], axis=0, ignore_index=True)       \n",
    "                print(f'File number {file_idx + 1} added to dataframe')\n",
    "    print('File import done')\n",
    "    return df_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kickstarter_data_short(datapath):\n",
    "    ''' \n",
    "    This is a version of the main function to load jsut 2 files for use in testing\n",
    "    datapath = location of csv files to be loaded\n",
    "    '''\n",
    "    # List with the names of all the csv files in the path\n",
    "    csv_files = glob.glob(datapath+'/*.csv')\n",
    "\n",
    "    print(f'Total files: {len(csv_files)}')\n",
    "\n",
    "    # Loop through the files\n",
    "    for file_idx, csv_file in enumerate(csv_files): \n",
    "        # create dataframe from 1st csv       \n",
    "        if file_idx == 0:\n",
    "            df_ks = pd.read_csv(csv_file)\n",
    "            print(f'File number {file_idx + 1} added to dataframe')\n",
    "        else:\n",
    "            # create dataframe from idx csv\n",
    "            df = pd.read_csv(csv_file)\n",
    "            # check files are all in same\n",
    "            if  np.all(df.columns == df_ks.columns) == False:\n",
    "                print(f'Column format of {csv_file} does not match {csv_files[0]}. Please check and try again')\n",
    "                return\n",
    "            else:\n",
    "                # append to initial dataframe                   \n",
    "                df_ks = pd.concat([df_ks, df], axis=0, ignore_index=True)       \n",
    "                print(f'File number {file_idx + 1} added to dataframe')\n",
    "                # This is here to prevent more than 2 files being loaded to save time in testing\n",
    "                break\n",
    "    print('File import done')\n",
    "    return df_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_data(data):\n",
    "    ''' This function extracts specific sub fields from json files embedded in columns of a dataframe\n",
    "        data: dataframe containing column with json data'''\n",
    "    data['category_name'] = pd.DataFrame.from_dict([json.loads(data[\"category\"][i])['name'] for i in range(data.shape[0])])\n",
    "    data['category_slug'] = pd.DataFrame([json.loads(data[\"category\"][i])['slug'] for i in range(data.shape[0])])\n",
    "    # TODO split slug into main category and sub category\n",
    "    data.drop(labels = 'category', axis=1, inplace=True)\n",
    "    \n",
    "    print('json columns extracted')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(data):\n",
    "    #Convert from unix time stamp to more readable time format\n",
    "    data['converted_deadline'] = pd.to_datetime(data['deadline'], unit='s')\n",
    "    data['converted_launched_at'] = pd.to_datetime(data['launched_at'], unit='s')\n",
    "    #Create project duration variable\n",
    "    data['project_duration_days'] = (data['converted_deadline'] - data['converted_launched_at']).dt.days\n",
    "    # Drop redundant columns\n",
    "    data.drop(columns=['deadline', 'launched_at'], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(data,target='state', new_target_var='success', success_label='successful'):\n",
    "    '''\n",
    "    creates a dummy variable out of the state to be used as dependant variable\n",
    "    '''\n",
    "    #data('success') = data['state'].apply(lambda x: 1 if x == 'successful' else 0)\n",
    "    data[new_target_var] = data[target].apply(lambda x: 1 if x == success_label else 0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_and_features(data, target_var='success'):\n",
    "    '''\n",
    "    Function that splits dataset into target and feature dataframes\n",
    "    '''\n",
    "    #target = data['success']\n",
    "    target = data[target_var]\n",
    "    data.drop([target_var,'state'], axis = 1, inplace=True)\n",
    "    features = data\n",
    "\n",
    "    print('target and features split is done')\n",
    "    return target, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def currency_conversion(data):\n",
    "    # Convert the currency of all projects to USD. \n",
    "    # We use static_usd_rate since this is what was used for usd_pledged\n",
    "    data['usd_goal'] = data['goal'] * data['static_usd_rate']\n",
    "    # drop goal and static_usd_rate to remove redundant data\n",
    "    data.drop(columns=['goal','static_usd_rate'], inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    '''\n",
    "    Create new features: Blurb length\n",
    "    '''\n",
    "    data['blurb_length'] = data.blurb.apply(lambda x: len(str(x)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(data, num_columns=['usd_goal','project_duration_days','blurb_length']):\n",
    "    ''' Initialize a scaler, then apply it to the features'''\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    data[num_columns] = scaler.fit_transform(data[num_columns])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(data):\n",
    "    '''remove unnecessary columns'''\n",
    "    # Drop due to many missing values\n",
    "    data.drop(columns = ['friends', 'is_backing', 'is_starred', 'permissions'], inplace=True)\n",
    "    # Some Json strings varariables with unusable or already used data\n",
    "    data.drop(columns = ['creator', 'location', 'photo', 'profile', 'slug', 'urls'], inplace=True)\n",
    "    # Columns that are not specific to the campaign or are redundant or are technical data unrelated to campaign\n",
    "    data.drop(columns = ['created_at','currency', 'currency_symbol', 'currency_trailing_code', \n",
    "                     'current_currency', 'disable_communication',\n",
    "                     'is_starrable', 'source_url', 'spotlight', 'staff_pick', \n",
    "                     'usd_type', 'state_changed_at','fx_rate'], inplace=True)\n",
    "    # drop columns due to being linked to dependent variable which would not be known in advance\n",
    "    data.drop(columns = [ 'converted_pledged_amount', 'pledged', 'usd_pledged','id'], inplace=True) # to be checked 'backers_count'\n",
    "    # drop columns that are not used                \n",
    "    data.drop(columns = ['blurb', 'name', 'converted_deadline', 'converted_launched_at','category_name'], inplace=True) #'category_slug'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split_kickstarter(features, target, test_size = 0.2, random_state = 0):\n",
    "    '''\n",
    "    Split data into train and test sets based on features and target dataframes.\n",
    "    Shows results of the split and returns four dataframes\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = test_size, random_state = random_state)\n",
    "    # Show the results of the split\n",
    "    print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "    print (\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_using_gini(X_train, y_train): \n",
    "  \n",
    "    # Creating the decision tree classifier object \n",
    "    clf_tree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            max_depth=3, min_samples_leaf=5) \n",
    "    # Performing training \n",
    "    clf_tree.fit(X_train, y_train) \n",
    "    return clf_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test data with model trained using either giniIndex\n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\\n\") \n",
    "    print(y_pred) \n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \\n\", \n",
    "    confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \\n\", \n",
    "    accuracy_score(y_test, y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \\n\", \n",
    "    classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 56\n",
      "File number 1 added to dataframe\n",
      "File number 2 added to dataframe\n",
      "File number 3 added to dataframe\n",
      "File number 4 added to dataframe\n",
      "File number 5 added to dataframe\n",
      "File number 6 added to dataframe\n",
      "File number 7 added to dataframe\n",
      "File number 8 added to dataframe\n",
      "File number 9 added to dataframe\n",
      "File number 10 added to dataframe\n",
      "File number 11 added to dataframe\n",
      "File number 12 added to dataframe\n",
      "File number 13 added to dataframe\n",
      "File number 14 added to dataframe\n",
      "File number 15 added to dataframe\n",
      "File number 16 added to dataframe\n",
      "File number 17 added to dataframe\n",
      "File number 18 added to dataframe\n",
      "File number 19 added to dataframe\n",
      "File number 20 added to dataframe\n",
      "File number 21 added to dataframe\n",
      "File number 22 added to dataframe\n",
      "File number 23 added to dataframe\n",
      "File number 24 added to dataframe\n",
      "File number 25 added to dataframe\n",
      "File number 26 added to dataframe\n",
      "File number 27 added to dataframe\n",
      "File number 28 added to dataframe\n",
      "File number 29 added to dataframe\n",
      "File number 30 added to dataframe\n",
      "File number 31 added to dataframe\n",
      "File number 32 added to dataframe\n",
      "File number 33 added to dataframe\n",
      "File number 34 added to dataframe\n",
      "File number 35 added to dataframe\n",
      "File number 36 added to dataframe\n",
      "File number 37 added to dataframe\n",
      "File number 38 added to dataframe\n",
      "File number 39 added to dataframe\n",
      "File number 40 added to dataframe\n",
      "File number 41 added to dataframe\n",
      "File number 42 added to dataframe\n",
      "File number 43 added to dataframe\n",
      "File number 44 added to dataframe\n",
      "File number 45 added to dataframe\n",
      "File number 46 added to dataframe\n",
      "File number 47 added to dataframe\n",
      "File number 48 added to dataframe\n",
      "File number 49 added to dataframe\n",
      "File number 50 added to dataframe\n",
      "File number 51 added to dataframe\n",
      "File number 52 added to dataframe\n",
      "File number 53 added to dataframe\n",
      "File number 54 added to dataframe\n",
      "File number 55 added to dataframe\n",
      "File number 56 added to dataframe\n",
      "File import done\n",
      "json columns extracted\n",
      "target and features split is done\n",
      "Training set has 161528 samples.\n",
      "Testing set has 40383 samples.\n",
      "Predicted values:\n",
      "\n",
      "[1 1 0 ... 1 0 0]\n",
      "Confusion Matrix: \n",
      " [[14301  2598]\n",
      " [  745 22739]]\n",
      "Accuracy : \n",
      " 91.72176410865958\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90     16899\n",
      "           1       0.90      0.97      0.93     23484\n",
      "\n",
      "    accuracy                           0.92     40383\n",
      "   macro avg       0.92      0.91      0.91     40383\n",
      "weighted avg       0.92      0.92      0.92     40383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" MAIN SCRIPT =============================================================\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Read data\n",
    "\n",
    "    df = load_kickstarter_data('kickstarter/data')\n",
    "    \n",
    "    # Extract category data from json\n",
    "    df = extract_json_data(df)\n",
    "    \n",
    "    # drop campaigns that are still ongoing\n",
    "    df = df[df.state != 'live'] # change this to sucessful and \n",
    "    \n",
    "    # convert unix timestamps and calculate campaign duration\n",
    "    df = get_duration(df)\n",
    "    \n",
    "    # Get blurb length\n",
    "    df = feature_engineering(df)\n",
    "    \n",
    "    #create goal data in single currency\n",
    "    df = currency_conversion(df)\n",
    "    \n",
    "    # encode target variable 'state' to numerical values, success is 1 all others are fail and 0\n",
    "    df = get_target(df,target='state', new_target_var='success', success_label='successful')\n",
    "\n",
    "    # drop unnecessary columns\n",
    "    df=drop_columns(df)\n",
    "    df.head()\n",
    "\n",
    "    # Split the data into features and target label\n",
    "    target, features = get_target_and_features(df)\n",
    "\n",
    "    # split categorical columns into dummies\n",
    "    features = pd.get_dummies(features, columns=['country', 'category_slug'], drop_first=True) #Avoid dummy trap   \n",
    "\n",
    "    # Clean and augment data\n",
    "    # scale numerical features\n",
    "    num_columns = ['usd_goal','project_duration_days']\n",
    "    features = scale_features(features, num_columns)\n",
    "    \n",
    "    # Split into training and test set\n",
    "    X_train, X_test, y_train, y_test = test_train_split_kickstarter(features, target, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    # Fit a simple decision tree first\n",
    "    clf_gini = train_using_gini(X_train, y_train) \n",
    "    \n",
    "    # Create predictions using simple model\n",
    "    y_pred = prediction(X_test, clf_object=clf_gini)\n",
    "    \n",
    "    # show results\n",
    "    cal_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-207559f8a33b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'blurb_length2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblurb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/nf_2nd_project/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-207559f8a33b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'blurb_length2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblurb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "df['blurb_length'] = df.blurb.apply(lambda x: len((x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers_count</th>\n",
       "      <th>country</th>\n",
       "      <th>category_slug</th>\n",
       "      <th>project_duration_days</th>\n",
       "      <th>blurb_length</th>\n",
       "      <th>usd_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>US</td>\n",
       "      <td>games/playing cards</td>\n",
       "      <td>0.325843</td>\n",
       "      <td>125</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271</td>\n",
       "      <td>US</td>\n",
       "      <td>music/rock</td>\n",
       "      <td>0.325843</td>\n",
       "      <td>108</td>\n",
       "      <td>0.000187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GB</td>\n",
       "      <td>games/playing cards</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>133</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>publishing/nonfiction</td>\n",
       "      <td>0.325843</td>\n",
       "      <td>121</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>US</td>\n",
       "      <td>music/classical music</td>\n",
       "      <td>0.325843</td>\n",
       "      <td>134</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   backers_count country          category_slug  project_duration_days  \\\n",
       "1             47      US    games/playing cards               0.325843   \n",
       "2            271      US             music/rock               0.325843   \n",
       "3              3      GB    games/playing cards               0.651685   \n",
       "4              3      US  publishing/nonfiction               0.325843   \n",
       "5             35      US  music/classical music               0.325843   \n",
       "\n",
       "   blurb_length  usd_goal  \n",
       "1           125  0.000012  \n",
       "2           108  0.000187  \n",
       "3           133  0.000152  \n",
       "4           121  0.000035  \n",
       "5           134  0.000044  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['backers_count', 'country', 'state', 'category_name', 'category_slug',\n",
      "       'project_duration_days', 'blurb_length', 'usd_goal', 'success'],\n",
      "      dtype='object')\n",
      "(7318, 9)\n",
      "(1464, 358)\n",
      "(1464,)\n",
      "(5854, 358)\n",
      "(5854,)\n",
      "int64\n",
      "(1464,)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of dataframes\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train.dtype)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      games/playing cards\n",
       "2               music/rock\n",
       "3      games/playing cards\n",
       "4    publishing/nonfiction\n",
       "5    music/classical music\n",
       "Name: category_slug, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category_slug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5ebc32fe86fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['success'] = df.state.apply(lambda x: True if x == 'successful' else False)\n",
    "df['match'] = df['success'] == df['reached_goal']\n",
    "df.query('state == \"successful\"').match.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff for figureing out exchange rates\n",
    "df['implied_fx_rate'] = df['usd_pledged'] / df['pledged']\n",
    "df[['usd_pledged','implied_fx_rate','fx_rate','static_usd_rate']].head(10)\n",
    "df['usd_goal'] = df['goal'] * df['static_usd_rate']\n",
    "df['reached_goal'] = df['usd_goal'] < df['usd_pledged']\n",
    "df['success'] = df.state.apply(lambda x: True if x == 'successful' else False)\n",
    "df['match'] = df['success'] == df['reached_goal']\n",
    "df.query('state == \"successful\" & usd_type == \"international\"').match.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf_2nd_project] *",
   "language": "python",
   "name": "conda-env-nf_2nd_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
