{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import glob\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kickstarter_data(datapath):\n",
    "    '''datapath = location of csv files to be loaded'''\n",
    "    # List with the names of all the csv files in the path\n",
    "    csv_files = glob.glob(datapath+'/*.csv')\n",
    "\n",
    "    print(f'Total files: {len(csv_files)}')\n",
    "\n",
    "    # Loop through the files\n",
    "    for file_idx, csv_file in enumerate(csv_files): \n",
    "        # create dataframe from 1st csv       \n",
    "        if file_idx == 0:\n",
    "            df_ks = pd.read_csv(csv_file)\n",
    "            print(f'File number {file_idx + 1} added to dataframe')\n",
    "        else:\n",
    "            # create dataframe from idx csv\n",
    "            df = pd.read_csv(csv_file)\n",
    "            # check files are all in same\n",
    "            if  np.all(df.columns == df_ks.columns) == False:\n",
    "                print(f'Column format of {csv_file} does not match {csv_files[0]}. Please check and try again')\n",
    "                return\n",
    "            else:\n",
    "                # append to initial dataframe                   \n",
    "                df_ks = pd.concat([df_ks, df], axis=0, ignore_index=True)       \n",
    "                print(f'File number {file_idx + 1} added to dataframe')\n",
    "    print('File import done')\n",
    "    return df_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kickstarter_data_short(datapath):\n",
    "    ''' \n",
    "    This is a version of the main function to load jsut 2 files for use in testing\n",
    "    datapath = location of csv files to be loaded\n",
    "    '''\n",
    "    # List with the names of all the csv files in the path\n",
    "    csv_files = glob.glob(datapath+'/*.csv')\n",
    "\n",
    "    print(f'Total files: {len(csv_files)}')\n",
    "\n",
    "    # Loop through the files\n",
    "    for file_idx, csv_file in enumerate(csv_files): \n",
    "        # create dataframe from 1st csv       \n",
    "        if file_idx == 0:\n",
    "            df_ks = pd.read_csv(csv_file)\n",
    "            print(f'File number {file_idx + 1} added to dataframe')\n",
    "        else:\n",
    "            # create dataframe from idx csv\n",
    "            df = pd.read_csv(csv_file)\n",
    "            # check files are all in same\n",
    "            if  np.all(df.columns == df_ks.columns) == False:\n",
    "                print(f'Column format of {csv_file} does not match {csv_files[0]}. Please check and try again')\n",
    "                return\n",
    "            else:\n",
    "                # append to initial dataframe                   \n",
    "                df_ks = pd.concat([df_ks, df], axis=0, ignore_index=True)       \n",
    "                print(f'File number {file_idx + 1} added to dataframe')\n",
    "                # This is here to prevent more than 2 files being loaded to save time in testing\n",
    "                break\n",
    "    print('File import done')\n",
    "    return df_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_data(data):\n",
    "    ''' This function extracts specific sub fields from json files embedded in columns of a dataframe\n",
    "        data: dataframe containing column with json data'''\n",
    "    data['category_slug'] = pd.DataFrame([json.loads(data[\"category\"][i])['slug'] for i in range(data.shape[0])])\n",
    "    data['category_name'] = pd.DataFrame.from_dict([json.loads(data[\"category\"][i])['name'] for i in range(data.shape[0])])\n",
    "    data.drop(labels = 'category', axis=1, inplace=True)\n",
    "    \n",
    "# other Jsons are not parsable by this method\n",
    "#    data['location_name'] = pd.DataFrame.from_dict([json.loads(data[\"location\"][i])['name'] for i in range(data.shape[0])])\n",
    "#    data['location_country'] = pd.DataFrame([json.loads(data[\"location\"][i])['country'] for i in range(data.shape[0])])\n",
    "#    data['creater_is_registered'] = pd.DataFrame([json.loads(data[\"creator\"][i])['is_registered'] for i in range(data.shape[0])])\n",
    "    print('json columns extracted')\n",
    "    return data\n",
    "# check output\n",
    "#df2 = extract_json_data(df)\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(data):\n",
    "    #Convert from unix time stamp to more readable time format\n",
    "    data['converted_deadline'] = pd.to_datetime(data['deadline'], unit='s')\n",
    "    data['converted_launched_at'] = pd.to_datetime(data['launched_at'], unit='s')\n",
    "    #Create project duration variable\n",
    "    data['project_duration_days'] = (data['converted_deadline'] - data['converted_launched_at']).dt.days\n",
    "    # Drop redundant columns\n",
    "    data.drop(columns=['deadline', 'launched_at'], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(data,target='state', new_target_var='success', success_label='successful'):\n",
    "    '''\n",
    "    creates a dummy variable out of the state\n",
    "    '''\n",
    "    data[new_target_var] = data[target].apply(lambda x: 1 if x == success_label else 0)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_features(data, target_var='success'):\n",
    "    '''\n",
    "    Function that splits dataset into target and feature dataframes\n",
    "    '''\n",
    "#    data.head()\n",
    "    target = data[target_var]\n",
    "#    target.head()\n",
    "#  data.drop([target_var,'state'], axis = 1, inplace=True)\n",
    "    features_raw = data\n",
    "#    features_raw.head()\n",
    "#    data.head()\n",
    "    print('target and features split is done')\n",
    "    return target, features_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(data, num_columns):\n",
    "    ''' Initialize a scaler, then apply it to the features'''\n",
    "    scaler = MinMaxScaler()\n",
    "    data[num_columns] = scaler.fit_transform(data[num_columns])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def currency_conversion(data):\n",
    "    #Convert the currency of all projects to USD\n",
    "    data['usd_goal'] = data['goal'] * data['static_usd_rate']\n",
    "    # drop goal and static_usd_rate to remove redundant data\n",
    "    data.drop(columns=['goal','static_usd_rate'], inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(data):\n",
    "    '''remove unnecessary columns'''\n",
    "    # Drop due to many missing values\n",
    "    data.drop(columns=['friends', 'is_backing', 'is_starred', 'permissions'], inplace=True)\n",
    "    # Some Json strings varariables with unusable or already used data\n",
    "    data.drop(columns=['creator', 'location', 'photo', 'profile', 'slug', 'urls'], inplace=True)\n",
    "    # Columns that are not specific to the campaign or are redundant or are technical data unrelated to campaign\n",
    "    data.drop(columns=['created_at','currency', 'currency_symbol', 'currency_trailing_code', \n",
    "                     'current_currency', 'disable_communication',\n",
    "                     'is_starrable', 'source_url', 'spotlight', 'staff_pick', \n",
    "                     'usd_type', 'state_changed_at','fx_rate'], inplace=True)\n",
    "    # drop columns due to being linked to dependent variable which would not be known in advance\n",
    "    data.drop(columns=['backers_count', 'converted_pledged_amount', 'pledged', 'usd_pledged','id',], inplace=True)\n",
    "    # drop columns that are not used                \n",
    "    data.drop(columns=['blurb', 'name', 'category_slug', 'converted_deadline', 'converted_launched_at'], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split_kickstarter(features, target, test_size = 0.2, random_state = 0):\n",
    "    '''\n",
    "    Split data into train and test sets based on features and target dataframes.\n",
    "    Shows results of the split and returns four dataframes\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = test_size, random_state = random_state)\n",
    "    # Show the results of the split\n",
    "    print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "    print (\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_using_gini(X_train, X_test, y_train): \n",
    "  \n",
    "    # Creating the classifier object \n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            max_depth=3, min_samples_leaf=5) \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test data with model trained using either giniIndex / or entropy\n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\\n\") \n",
    "    print(y_pred) \n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \\n\", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \\n\", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \\n\", \n",
    "    classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 56\n",
      "File number 1 added to dataframe\n",
      "File number 2 added to dataframe\n",
      "File import done\n",
      "json columns extracted\n",
      "target and features split is done\n",
      "Training set has 5854 samples.\n",
      "Testing set has 1464 samples.\n",
      "Predicted values:\n",
      "\n",
      "[1 0 0 ... 1 0 0]\n",
      "Confusion Matrix: \n",
      " [[583   0]\n",
      " [  0 881]]\n",
      "Accuracy : \n",
      " 100.0\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       583\n",
      "           1       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      1464\n",
      "   macro avg       1.00      1.00      1.00      1464\n",
      "weighted avg       1.00      1.00      1.00      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" MAIN SCRIPT =============================================================\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Read data\n",
    "\n",
    "    df = load_kickstarter_data_short('kickstarter/data')\n",
    "    \n",
    "    # Extract data from json\n",
    "    df = extract_json_data(df)\n",
    "    \n",
    "    # drop campaigns that are still ongoing\n",
    "    df = df[df.state != 'live']\n",
    "    \n",
    "    # convert unix timestamps and calculate campaign duration\n",
    "    df = get_duration(df)\n",
    "    \n",
    "    #create goal data in single currency\n",
    "    df = currency_conversion(df)\n",
    "    \n",
    "    # encode target variable 'state' to numerical values, success is 1 all others are fail and 0\n",
    "    df = get_target(df,target='state', new_target_var='success', success_label='successful')\n",
    "\n",
    "    # drop unnecessary columns\n",
    "    df=drop_columns(df)\n",
    "    df.head()\n",
    "\n",
    "    # Split the data into features and target label\n",
    "    target, features_raw = get_target_features(df)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # split categorical columns into dummies\n",
    "    features_raw = pd.get_dummies(features_raw)    \n",
    "\n",
    "    # Clean and augment data\n",
    "    # scale numerical features\n",
    "#    num_columns = ['goal']\n",
    "#    features_raw = scale_features(df, num_columns)\n",
    "    \n",
    "    # Split into training and test set\n",
    "    X_train, X_test, y_train, y_test = test_train_split_kickstarter(features_raw, target, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    # Fit a simple decision tree first\n",
    "    clf_gini = train_using_gini(X_train, X_test, y_train) \n",
    "    \n",
    "    # Create predictions using simple model\n",
    "    y_pred = prediction(X_test, clf_gini)\n",
    "    \n",
    "    # show results\n",
    "    cal_accuracy(y_test, y_pred)\n",
    "    \n",
    "    # Creating the classifier object \n",
    "\n",
    "\n",
    "    # Fit Adaboost classifier using a decision tree as base estimator\n",
    "    # Test with different number of iterations\n",
    "    # Append the score output from each iteration of the adboost function\n",
    "    \n",
    "    # Compare error rate vs number of iterations\n",
    "    #   plot_error_rate(er_train, er_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>category_name</th>\n",
       "      <th>project_duration_days</th>\n",
       "      <th>usd_goal</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>successful</td>\n",
       "      <td>Playing Cards</td>\n",
       "      <td>30</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>successful</td>\n",
       "      <td>Rock</td>\n",
       "      <td>30</td>\n",
       "      <td>15000.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GB</td>\n",
       "      <td>failed</td>\n",
       "      <td>Playing Cards</td>\n",
       "      <td>59</td>\n",
       "      <td>12160.6569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>successful</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>30</td>\n",
       "      <td>2800.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>successful</td>\n",
       "      <td>Classical Music</td>\n",
       "      <td>30</td>\n",
       "      <td>3500.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country       state    category_name  project_duration_days    usd_goal  \\\n",
       "1      US  successful    Playing Cards                     30   1000.0000   \n",
       "2      US  successful             Rock                     30  15000.0000   \n",
       "3      GB      failed    Playing Cards                     59  12160.6569   \n",
       "4      US  successful       Nonfiction                     30   2800.0000   \n",
       "5      US  successful  Classical Music                     30   3500.0000   \n",
       "\n",
       "   success  \n",
       "1        1  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  \n",
       "5        1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['country', 'state', 'category_name', 'project_duration_days',\n",
      "       'usd_goal', 'success'],\n",
      "      dtype='object')\n",
      "(7318, 6)\n",
      "(1464, 187)\n",
      "(1464,)\n",
      "(5854, 187)\n",
      "(5854,)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Check shape of dataframes\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'category_slug', 'category_name', 'converted_deadline',\n",
       "       'converted_launched_at', 'project_duration_days', 'usd_goal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['success'] = df.state.apply(lambda x: True if x == 'successful' else False)\n",
    "df['match'] = df['success'] == df['reached_goal']\n",
    "df.query('state == \"successful\"').match.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     2084\n",
       "False      53\n",
       "Name: match, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stuff for figureing out exchange rates\n",
    "df['implied_fx_rate'] = df['usd_pledged'] / df['pledged']\n",
    "df[['usd_pledged','implied_fx_rate','fx_rate','static_usd_rate']].head(10)\n",
    "df['usd_goal'] = df['goal'] * df['static_usd_rate']\n",
    "df['reached_goal'] = df['usd_goal'] < df['usd_pledged']\n",
    "df['success'] = df.state.apply(lambda x: True if x == 'successful' else False)\n",
    "df['match'] = df['success'] == df['reached_goal']\n",
    "df.query('state == \"successful\" & usd_type == \"international\"').match.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf_2nd_project] *",
   "language": "python",
   "name": "conda-env-nf_2nd_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
